{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAMELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data used to train the neural network was gathered from the Cosmology and Astrophysics with MachinE Learning Simulations (CAMELS). CAMELS contains 6325 cosmological organized in different suits:     \n",
    "\n",
    "- magnetohydrodynamic:\n",
    "    - IllustrisTNG\n",
    "    - SIMBA\n",
    "    - Astrid\n",
    "- N-body\n",
    "\n",
    "Each suit is split into 4 different simulation sets:\n",
    "\n",
    "- LH (Latin-Hypercube): 1000 simulations with different values of the cosmological and astrophysical parameters which are arranged in a latin-hypercube. The initial conditions of each simulation are also different.\n",
    "- 1P (1-parameter at a time): 61 simulations where the values of the cosmological and astrophysical parameters are varied one at a time. The initial conditions of each simulation are the same.\n",
    "- CV (Cosmic Variance): 27 simulations where the cosomological and astrophysical parameters are fixed but the initial conditions vary.\n",
    "- EX (Extreme): 4 simulations with fixed cosmological parameters but different astrophysical parameters\n",
    "\n",
    "CAMELS vary 2 cosmological and 4 astrophysical parameters:\n",
    "\n",
    "- cosmological:\n",
    "    - $\\Omega_m$: Description. range of variation: $0.1 \\leq \\Omega_m \\leq 0.5$\n",
    "    - $\\sigma_8$: Description. range of variation: $0.6 \\leq \\sigma_8 \\leq 1.0$\n",
    "\n",
    "- astrophysical:\n",
    "    - $A_{SN1}$: Description. range of variation: $0.25 \\leq A_{SN1} \\leq 4.0$\n",
    "    - $A_{SN2}$: Description. range of variation: $0.50 \\leq A_{SN2} \\leq 2.0$\n",
    "    - $A_{GN1}$: Description. range of variation: $0.25 \\leq A_{GN1} \\leq 4.0$\n",
    "    - $A_{GN2}$: Description. range of variation: $0.50 \\leq A_{GN2} \\leq 2.0$\n",
    "\n",
    "Each hydrodynamic simulation evolves 256³ dark matter particles and 256³ gas resolution elements within a periodic comoving volume of 25 h⁻¹Mpc³ from a redshift z= 127 to z=0. During the evolution snapshots of the universe as a function of the redshift are created. In this work just data from the final snapshot, which corresponds to our universe at its current state, were used. We also restrict the data for the purpose of reasonable computation duration to IllustrisTNG-CV simulations. Details zu fof subfindhalos??\n",
    "Further details on the project and its goals are explained in [quelle: simulation_data.pdf][website]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes in h5py files containing a tremendous amount of information(quelle: https://www.tng-project.org/data/docs/specifications/#sec2\n",
    ") on the halos and subhalos (galaxies) of the simulated universe. Since we are intereseted in infering the mass of a halo from a few distinct properties of its subhalos we must extract the desired features:\n",
    "- halo features:\n",
    "    - Halo mass\n",
    "    - normalized 3D position\n",
    "    - normalized 3D velocity\n",
    "- subhalo features\n",
    "    - Mass of star & wind particles ?? whyyy\n",
    "    - Half mass radius\n",
    "    - normalized 3D position\n",
    "    - normalized 3D velocity\n",
    "\n",
    "Since we are interested in only halos containing mass, subhalos that contain a minimum of stellar particles and have mass restrictions are built in. The function \"general_tab\" does this and outputs a table containing the subhalo features and the halo properties mass, 3D velocity, 3D position and the relevant halo-indices.\n",
    "\n",
    "In some cases hosting halos close to boundaries can have subhalos on the other extreme of due to the periodic boundary conditions, which occur in the simulation. The function \"correct_boundary\" fixes this by subtracting or adding a boxlength to the 3D position.\n",
    "\n",
    "In order to validate the neural net on a dataset, which was not used for training, the data is split into training and validation set, which then are seperated into batches for computing the loss more efficient. The function \"split_dataset\" deals with this. (umformulieren weiß jz nd wie xd). \n",
    "\n",
    "The routine \"create_dataset\" builds the fully prepared dataset. For every subhalo contained in a relevant hosting halo (only halos with more than one subhalo) the positions and velocities are changed with their respective relative to the host halo ones. The 3D velocity is then replaced with its magnitude. Together with the global host halo properties number of subhalos and mass a graph (nodes = subhalos) for each hosting halo is created and appended to the dataset. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general tab\n",
    "import h5py\n",
    "import numpy as np\n",
    "from constants import *\n",
    "\n",
    "#--- NORMALIZATION ---#\n",
    "\n",
    "Nstar_th = 10   # Minimum number of stellar particles required to consider a galaxy\n",
    "radnorm = 8.    # Ad hoc normalization for half-mass radius\n",
    "velnorm = 100.  # Ad hoc normalization for velocity. Use velnorm=1. for galcen_frame=1\n",
    "\n",
    "def general_tab(path):\n",
    "\n",
    "    # Read hdf5 file\n",
    "    f = h5py.File(path, 'r')\n",
    "\n",
    "    # Load subhalo features\n",
    "    #types = (Gas, Dark Matter, unused, Tracers, Stars & Wind particles, Black holes)Quelle: https://www.tng-project.org/data/docs/specifications/#sec2\n",
    "    SubhaloPos = f[\"Subhalo/SubhaloPos\"][:]/boxsize\n",
    "    SubhaloMassType = f[\"Subhalo/SubhaloMassType\"][:,4]\n",
    "    SubhaloVel = f[\"Subhalo/SubhaloVel\"][:]/velnorm\n",
    "    SubhaloHalfmassRadType = f[\"Subhalo/SubhaloHalfmassRadType\"][:,4]/radnorm\n",
    "    #  just for restriction or classification\n",
    "    SubhaloLenType = f[\"Subhalo/SubhaloLenType\"][:,4]\n",
    "    HaloID = np.array(f[\"Subhalo/SubhaloGrNr\"][:], dtype=np.int32)\n",
    "    \n",
    "    # Load halo features\n",
    "    HaloMass = f[\"Group/Group_M_Crit200\"][:]\n",
    "    GroupPos = f[\"Group/GroupPos\"][:]/boxsize\n",
    "    GroupVel = f[\"Group/GroupVel\"][:]/velnorm\n",
    "\n",
    "    # Create general table with subhalo properties\n",
    "    # Host halo ID, 3D position, stellar mass, number of stellar particles, stellar half-mass radius, 3D velocity\n",
    "    tab = np.column_stack((HaloID, SubhaloPos, SubhaloMassType, SubhaloLenType, SubhaloHalfmassRadType, SubhaloVel))\n",
    "\n",
    "    # Restrictions:\n",
    "    indexes = np.argwhere(HaloMass>0.).reshape(-1)  # Neglect halos with zero mass\n",
    "    tab = tab[tab[:,4]>0.]                          # restrict to subhalos with mass (stars)\n",
    "    tab = tab[tab[:,5]>Nstar_th]                    # restrict to subhalos with a minimum of star/wind particles\n",
    "\n",
    "    tab[:,4] = np.log10(tab[:,4])                   # take the log of the stellar mass\n",
    "\n",
    "    # Once restricted to a minimum number of stellar particles, remove this feature since it is not observable\n",
    "    tab = np.delete(tab, 5, 1)\n",
    "    f.close()\n",
    "    return tab, HaloMass, GroupPos, GroupVel, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_boundary\n",
    "# Some halos close to a boundary could have subhalos at the other extreme of the box, due to periodic boundary conditions\n",
    "# Just add or substract a length boxe in such cases to correct this artifact\n",
    "def correct_boundary(pos, boxlength=1.):\n",
    "\n",
    "    for i, pos_i in enumerate(pos):\n",
    "        for j, coord in enumerate(pos_i):\n",
    "            if coord > boxlength/2.:\n",
    "                pos[i,j] -= boxlength\n",
    "            elif -coord > boxlength/2.:\n",
    "                pos[i,j] += boxlength\n",
    "\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import random\n",
    "\n",
    "def split_datasets(dataset):\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    num_train = len(dataset)\n",
    "    split_valid = int(np.floor(valid_size * num_train))\n",
    "    split_test = split_valid + int(np.floor(test_size * num_train))\n",
    "\n",
    "    train_dataset = dataset[split_test:]\n",
    "    valid_dataset = dataset[:split_valid]\n",
    "    test_dataset = dataset[split_valid:split_test]\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(simsuite = \"IllustrisTNG\", simset = \"CV\", n_sims = 27):\n",
    "\n",
    "    simpath = simpathroot + simsuite + \"/\"+simset+\"_\"\n",
    "    print(\"Using \"+simsuite+\" simulation suite, \"+simset+\" set, \"+str(n_sims)+\" simulations.\")\n",
    "\n",
    "    dataset = []\n",
    "    subs = 0    # Number of subhalos\n",
    "\n",
    "    for sim in range(n_sims):\n",
    "\n",
    "        path = simpath + str(sim)+\"/fof_subhalo_tab_033.hdf5\"\n",
    "\n",
    "        # Load the table of galactic features from a single simulation\n",
    "        tab, HaloMass, HaloPos, HaloVel, halolist = general_tab(path)\n",
    "\n",
    "        # For each halo in the simulation:\n",
    "        for ind in halolist:\n",
    "\n",
    "            # Select subhalos within a halo with index ind\n",
    "            tab_halo = tab[tab[:,0]==ind][:,1:] #1upwards because we don't need the hosthalo id from original tab\n",
    "\n",
    "            # Consider only halos with at least one satellite galaxy (besides the central)\n",
    "            if tab_halo.shape[0]>1:\n",
    "\n",
    "                # write the positions and velocities as the relative position and velocity to the host halo\n",
    "                tab_halo[:,0:3] -= HaloPos[ind]\n",
    "                tab_halo[:,-3:] -= HaloVel[ind]\n",
    "\n",
    "                # Correct periodic boundary effects\n",
    "                tab_halo[:,:3] = correct_boundary(tab_halo[:,:3])\n",
    "\n",
    "                # compute the magnitude of the velocities and create a new table with these values\n",
    "                subhalovel = np.log10(np.sqrt(np.sum(tab_halo[:,-3:]**2., 1)))  # use this way in case you normalize velocities\n",
    "                newtab = np.column_stack((tab_halo[:,:-3], subhalovel))\n",
    "\n",
    "                # Take as global quantities of the halo the number of subhalos and the total stellar mass\n",
    "                u = np.zeros((1,2), dtype=np.float32)\n",
    "                u[0,0] = tab_halo.shape[0]  # number of subhalos\n",
    "                u[0,1] = np.log10(np.sum(10.**tab_halo[:,3]))\n",
    "\n",
    "                # Create the graph of the halo\n",
    "                # x: features (includes positions), pos: positions, u: global quantity\n",
    "                graph = Data(x=torch.tensor(newtab, dtype=torch.float32), pos=torch.tensor(tab_halo[:,:3], dtype=torch.float32), y=torch.tensor(np.log10(HaloMass[ind]), dtype=torch.float32), u=torch.tensor(u, dtype=torch.float))\n",
    "\n",
    "                # Update the total number of subhalos\n",
    "                subs += graph.x.shape[0]\n",
    "\n",
    "                dataset.append(graph)\n",
    "\n",
    "    print(\"Total number of halos\", len(dataset), \"Total number of subhalos\", subs)\n",
    "\n",
    "    # Number of features\n",
    "    node_features = newtab.shape[1]\n",
    "\n",
    "    return dataset, node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
